import { loggerService } from '@logger'
import type { Usage } from '@renderer/types'
import type { Chunk } from '@renderer/types/chunk'
import { ChunkType } from '@renderer/types/chunk'

import type { CompletionsParams, CompletionsResult, GenericChunk } from '../schemas'
import type { CompletionsContext, CompletionsMiddleware } from '../types'

export const MIDDLEWARE_NAME = 'FinalChunkConsumerAndNotifierMiddleware'

const logger = loggerService.withContext('FinalChunkConsumerMiddleware')

/**
 * æœ€ç»ˆChunkæ¶ˆè´¹å’Œé€šçŸ¥ä¸­é—´ä»¶
 *
 * èŒè´£ï¼š
 * 1. æ¶ˆè´¹æ‰€æœ‰GenericChunkæµä¸­çš„chunkså¹¶è½¬å‘ç»™onChunkå›è°ƒ
 * 2. ç´¯åŠ usage/metricsæ•°æ®ï¼ˆä»åŸå§‹SDK chunksæˆ–GenericChunkä¸­æå–ï¼‰
 * 3. åœ¨æ£€æµ‹åˆ°LLM_RESPONSE_COMPLETEæ—¶å‘é€åŒ…å«ç´¯è®¡æ•°æ®çš„BLOCK_COMPLETE
 * 4. å¤„ç†MCPå·¥å…·è°ƒç”¨çš„å¤šè½®è¯·æ±‚ä¸­çš„æ•°æ®ç´¯åŠ 
 */
const FinalChunkConsumerMiddleware: CompletionsMiddleware =
  () =>
  (next) =>
  async (ctx: CompletionsContext, params: CompletionsParams): Promise<CompletionsResult> => {
    const isRecursiveCall =
      params._internal?.toolProcessingState?.isRecursiveCall ||
      ctx._internal?.toolProcessingState?.isRecursiveCall ||
      false

    // åˆå§‹åŒ–ç´¯è®¡æ•°æ®ï¼ˆåªåœ¨é¡¶å±‚è°ƒç”¨æ—¶åˆå§‹åŒ–ï¼‰
    if (!isRecursiveCall) {
      if (!ctx._internal.customState) {
        ctx._internal.customState = {}
      }
      ctx._internal.observer = {
        usage: {
          prompt_tokens: 0,
          completion_tokens: 0,
          total_tokens: 0
        },
        metrics: {
          completion_tokens: 0,
          time_completion_millsec: 0,
          time_first_token_millsec: 0,
          time_thinking_millsec: 0
        }
      }
      // åˆå§‹åŒ–æ–‡æœ¬ç´¯ç§¯å™¨
      ctx._internal.customState.accumulatedText = ''
      ctx._internal.customState.startTimestamp = Date.now()
    }

    // è°ƒç”¨ä¸‹æ¸¸ä¸­é—´ä»¶
    const result = await next(ctx, params)

    // ğŸ”§ å…³é”®ä¿®å¤ï¼šé€’å½’è°ƒç”¨æ—¶ä¸æ¶ˆè´¹æµï¼Œç›´æ¥è¿”å›ç»™è°ƒç”¨è€…ï¼ˆVCPToolExecutorMiddleware.executeToolsIfNeededï¼‰
    // è¿™æ · depth 0 å¯ä»¥æ­£ç¡®è¯»å– depth 1 çš„æµæ•°æ®å¹¶å…¥é˜Ÿåˆ° TransformStream
    if (isRecursiveCall) {
      logger.debug('Recursive call detected, passing stream through without consuming')
      return result
    }

    // å“åº”åå¤„ç†ï¼šå¤„ç†GenericChunkæµå¼å“åº”ï¼ˆä»…åœ¨é¡¶å±‚è°ƒç”¨æ—¶ï¼‰
    if (result.stream) {
      const resultFromUpstream = result.stream

      if (resultFromUpstream && resultFromUpstream instanceof ReadableStream) {
        const reader = resultFromUpstream.getReader()

        try {
          while (true) {
            const { done, value: chunk } = await reader.read()
            logger.silly('chunk', chunk)
            if (done) {
              logger.debug(`Input stream finished.`)
              break
            }

            if (chunk) {
              const genericChunk = chunk as GenericChunk
              // æå–å¹¶ç´¯åŠ usage/metricsæ•°æ®
              extractAndAccumulateUsageMetrics(ctx, genericChunk)

              params.onChunk?.(genericChunk)
            } else {
              logger.warn(`Received undefined chunk before stream was done.`)
            }
          }
        } catch (error: any) {
          logger.error(`Error consuming stream:`, error as Error)
          // FIXME: ä¸´æ—¶è§£å†³æ–¹æ¡ˆã€‚è¯¥ä¸­é—´ä»¶çš„å¼‚å¸¸æ— æ³•è¢« ErrorHandlerMiddlewareæ•è·ã€‚
          if (params.onError) {
            params.onError(error)
          }
          if (params.shouldThrow) {
            throw error
          }
        } finally {
          if (params.onChunk) {
            params.onChunk({
              type: ChunkType.BLOCK_COMPLETE,
              response: {
                usage: ctx._internal.observer?.usage ? { ...ctx._internal.observer.usage } : undefined,
                metrics: ctx._internal.observer?.metrics ? { ...ctx._internal.observer.metrics } : undefined
              }
            } as Chunk)
            if (ctx._internal.toolProcessingState) {
              ctx._internal.toolProcessingState = {}
            }
          }
        }

        // ä¸ºæµå¼è¾“å‡ºæ·»åŠ getTextæ–¹æ³•
        const modifiedResult = {
          ...result,
          stream: new ReadableStream<GenericChunk>({
            start(controller) {
              controller.close()
            }
          }),
          getText: (): string => {
            return (ctx._internal.customState?.accumulatedText as string) || ''
          }
        }

        return modifiedResult as typeof result
      } else {
        logger.debug(`No GenericChunk stream to process.`)
      }
    }

    return result
  }

/**
 * ä»GenericChunkæˆ–åŸå§‹SDK chunksä¸­æå–usage/metricsæ•°æ®å¹¶ç´¯åŠ 
 */
function extractAndAccumulateUsageMetrics(ctx: CompletionsContext, chunk: GenericChunk): void {
  if (!ctx._internal.observer?.usage || !ctx._internal.observer?.metrics) {
    return
  }

  try {
    if (ctx._internal.customState && !ctx._internal.customState?.firstTokenTimestamp) {
      ctx._internal.customState.firstTokenTimestamp = Date.now()
      logger.debug(`First token timestamp: ${ctx._internal.customState.firstTokenTimestamp}`)
    }
    if (chunk.type === ChunkType.LLM_RESPONSE_COMPLETE) {
      // ä»LLM_RESPONSE_COMPLETE chunkä¸­æå–usageæ•°æ®
      if (chunk.response?.usage) {
        accumulateUsage(ctx._internal.observer.usage, chunk.response.usage)
      }

      if (ctx._internal.customState && ctx._internal.customState?.firstTokenTimestamp) {
        const firstTokenTimestamp = ctx._internal.customState.firstTokenTimestamp as number
        const startTimestamp = ctx._internal.customState.startTimestamp as number
        ctx._internal.observer.metrics.time_first_token_millsec = firstTokenTimestamp - startTimestamp
        ctx._internal.observer.metrics.time_completion_millsec += Date.now() - firstTokenTimestamp
      }
    }

    // ä¹Ÿå¯ä»¥ä»å…¶ä»–chunkç±»å‹ä¸­æå–metricsæ•°æ®
    if (chunk.type === ChunkType.THINKING_COMPLETE && chunk.thinking_millsec && ctx._internal.observer?.metrics) {
      ctx._internal.observer.metrics.time_thinking_millsec = Math.max(
        ctx._internal.observer.metrics.time_thinking_millsec || 0,
        chunk.thinking_millsec
      )
    }
  } catch (error) {
    logger.error('Error extracting usage/metrics from chunk:', error as Error)
  }
}

/**
 * ç´¯åŠ usageæ•°æ®
 */
function accumulateUsage(accumulated: Usage, newUsage: Usage): void {
  if (newUsage.prompt_tokens !== undefined) {
    accumulated.prompt_tokens += newUsage.prompt_tokens
  }
  if (newUsage.completion_tokens !== undefined) {
    accumulated.completion_tokens += newUsage.completion_tokens
  }
  if (newUsage.total_tokens !== undefined) {
    accumulated.total_tokens += newUsage.total_tokens
  }
  if (newUsage.thoughts_tokens !== undefined) {
    accumulated.thoughts_tokens = (accumulated.thoughts_tokens || 0) + newUsage.thoughts_tokens
  }
  // Handle OpenRouter specific cost fields
  if (newUsage.cost !== undefined) {
    accumulated.cost = (accumulated.cost || 0) + newUsage.cost
  }
}

export default FinalChunkConsumerMiddleware
